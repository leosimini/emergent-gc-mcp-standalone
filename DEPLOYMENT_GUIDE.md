# ğŸš€ GuÃ­a de Deployment - MCP Server Standalone

## ğŸ“‹ **Resumen de la SoluciÃ³n**

Hemos creado un proyecto MCP Server **completamente independiente** que se puede deployar por separado del proyecto principal. Esto soluciona los problemas arquitecturales identificados:

âœ… **Puerto independiente**: Se deploya en puerto estÃ¡ndar (80/443)  
âœ… **Subdominio propio**: `mcp.tudominio.com`  
âœ… **ConexiÃ³n configurable**: Puede conectarse a dev/staging/prod del Agent API  
âœ… **Transferencia de API key**: Valida API keys contra el backend principal  

## ğŸ—ï¸ **Arquitectura Final**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Claude Desktop    â”‚    â”‚  MCP Server         â”‚    â”‚  Gastos Compartidos â”‚
â”‚   Cursor IDE        â”‚â”€â”€â”€â–¶â”‚  mcp.tudominio.com  â”‚â”€â”€â”€â–¶â”‚  tudominio.com      â”‚
â”‚   Custom LLM        â”‚    â”‚  (Proyecto Standalone) â”‚  â”‚  /api/agent/v1/*    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  API Key Validation â”‚
                           â”‚  User Context Pass  â”‚
                           â”‚  Request Proxying   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ **CÃ³digo Preparado para Copiar**

Todo el cÃ³digo estÃ¡ listo en: `/app/mcp-server-standalone/`

### **Estructura del Proyecto Standalone:**
```
mcp-server-standalone/
â”œâ”€â”€ package.json              # Dependencias y scripts
â”œâ”€â”€ .env.example              # ConfiguraciÃ³n de ejemplo
â”œâ”€â”€ vercel.json               # Config para Vercel
â”œâ”€â”€ Dockerfile                # Config para Docker
â”œâ”€â”€ README.md                 # DocumentaciÃ³n completa
â”œâ”€â”€ DEPLOYMENT_GUIDE.md       # Esta guÃ­a
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.js             # Servidor principal
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ environment.js    # ConfiguraciÃ³n por entorno
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â””â”€â”€ api-key-auth.js   # ValidaciÃ³n de API keys
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ logger.js         # Sistema de logging
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ base-tool.js      # Clase base para tools
â”‚       â”œâ”€â”€ list-my-sheets.js # Herramienta listar hojas
â”‚       â””â”€â”€ get-sheet-summary.js # Herramienta resumen
â””â”€â”€ logs/                     # Directorio de logs
```

## ğŸ”§ **ConfiguraciÃ³n de ConexiÃ³n con Agent API**

### **Variables de Entorno CrÃ­ticas:**

```bash
# Para conectar a DESARROLLO
AGENT_API_URL=https://expense-wizard-103.preview.emergentagent.com

# Para conectar a PRODUCCIÃ“N  
AGENT_API_URL=https://gastoscompartidos.ai

# El MCP server automÃ¡ticamente usa:
# - /api/mcp/validate-key para validar API keys
# - /api/agent/v1/* para herramientas
```

### **Transferencia de API Key:**

1. **Usuario obtiene API key** del perfil en la app principal
2. **LLM cliente usa API key** en requests al MCP server
3. **MCP server valida API key** contra el backend principal
4. **MCP server obtiene contexto** del usuario (ID, permisos, etc.)
5. **MCP server ejecuta herramientas** con contexto del usuario

## ğŸš€ **Pasos para Deployment**

### **Paso 1: Copiar CÃ³digo**
```bash
# En tu mÃ¡quina local
cp -r /app/mcp-server-standalone /ruta/local/gastoscompartidos-mcp-server
cd /ruta/local/gastoscompartidos-mcp-server

# Crear nuevo repositorio Git
git init
git add .
git commit -m "Initial MCP Server standalone"
git remote add origin https://github.com/tu-usuario/gastoscompartidos-mcp-server.git
git push -u origin main
```

### **Paso 2: Configurar Environment**
```bash
cp .env.example .env

# Editar .env con tus valores:
NODE_ENV=production
AGENT_API_URL=https://gastoscompartidos.ai  # Tu dominio principal
PORT=8080
```

### **Paso 3: Deploy en Vercel (Recomendado)**
```bash
# Instalar Vercel CLI
npm i -g vercel

# Deploy
vercel

# Configurar variables de entorno en Vercel Dashboard:
# NODE_ENV: production
# AGENT_API_URL: https://gastoscompartidos.ai
```

### **Paso 4: Configurar Subdominio**
```bash
# En tu DNS provider (Cloudflare, etc.)
# Agregar CNAME record:
mcp.gastoscompartidos.ai â†’ tu-proyecto.vercel.app
```

## ğŸ§ª **Testing del Deployment**

### **1. Health Check**
```bash
curl https://mcp.gastoscompartidos.ai/health
```

**Respuesta esperada:**
```json
{
  "status": "healthy",
  "service": "gastoscompartidos-mcp-server",
  "environment": "production",
  "backend": {
    "agent_api_url": "https://gastoscompartidos.ai",
    "connectivity": "ok"
  }
}
```

### **2. Schema Discovery**
```bash
curl https://mcp.gastoscompartidos.ai/mcp/schema
```

### **3. API Key Validation**
```bash
# Usar API key real del perfil de usuario
curl -H "Authorization: Bearer gcp_real_api_key" \
     https://mcp.gastoscompartidos.ai/mcp/tools
```

### **4. Tool Execution**
```bash
curl -X POST \
     -H "Authorization: Bearer gcp_real_api_key" \
     -H "Content-Type: application/json" \
     -d '{"arguments": {"filter": "all"}}' \
     https://mcp.gastoscompartidos.ai/mcp/tools/list_my_sheets
```

## ğŸ”— **ConfiguraciÃ³n Final para LLM**

### **URL para conectar tu LLM:**
```
https://mcp.gastoscompartidos.ai
```

### **API Key:**
- Obtenida del perfil del usuario en `https://gastoscompartidos.ai/app/profile`
- Formato: `gcp_xxxxxxxxxxxx`

### **Endpoints disponibles:**
- `GET /health` - Health check
- `GET /mcp/schema` - Auto-discovery
- `GET /mcp/tools` - Listar herramientas
- `POST /mcp/tools/{name}` - Ejecutar herramienta

## ğŸ“Š **Monitoring & Maintenance**

### **Logs de Vercel:**
```bash
vercel logs --follow
```

### **Health Monitoring:**
- Health endpoint incluye test de conectividad con backend
- Logs estructurados con informaciÃ³n de environment
- Cache statistics de API keys

### **Performance:**
- Rate limiting: 100 req/min por IP
- API key caching: 5 minutos TTL
- Request timeout: 30 segundos
- Log rotation automÃ¡tica

## ğŸ”’ **Consideraciones de Seguridad**

1. **API Key Security**: Se validan contra backend principal
2. **Environment Isolation**: Variables separadas dev/prod
3. **CORS Configuration**: OrÃ­genes especÃ­ficos en prod
4. **Rate Limiting**: Por IP y por API key
5. **Audit Logging**: Todos los requests loggeados

## âœ… **Checklist Final**

- [ ] CÃ³digo copiado a nuevo repositorio
- [ ] Variables de entorno configuradas
- [ ] Deployment realizado (Vercel/Railway/Custom)
- [ ] Subdominio configurado
- [ ] Health check funcionando
- [ ] API key validation funcionando
- [ ] Tool execution funcionando
- [ ] LLM client configurado
- [ ] Monitoring configurado

## ğŸ“ **URLs Finales**

- **MCP Server**: `https://mcp.gastoscompartidos.ai`
- **Health Check**: `https://mcp.gastoscompartidos.ai/health`
- **Schema**: `https://mcp.gastoscompartidos.ai/mcp/schema`
- **Backend**: `https://gastoscompartidos.ai` (configurado en AGENT_API_URL)

---

## ğŸ¯ **ConclusiÃ³n**

Con esta configuraciÃ³n:
1. âœ… **MCP Server independiente** deployado en subdominio
2. âœ… **Puerto estÃ¡ndar** (80/443) accesible por LLMs
3. âœ… **ConexiÃ³n configurable** a diferentes entornos del Agent API
4. âœ… **API Key transferencia** automÃ¡tica y segura
5. âœ… **Escalabilidad** independiente del proyecto principal

Tu LLM podrÃ¡ conectarse a `https://mcp.gastoscompartidos.ai` usando la API key del usuario y acceder a todas las funcionalidades de gastos compartidos de manera segura.